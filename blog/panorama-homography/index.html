<!doctype html>
<html class="no-js" lang="">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <title>Delta Thoughts - Pleasing Panormas and Matrix Multiplication</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#FFFFFF" />

        <link rel="apple-touch-icon" href="/img/apple-touch-icon-precomposed.png">
        <link rel="icon" type="image/png" href="/img/favicon.png">
        <link rel="stylesheet" href="/css/main.css">
    </head>
    <body>
        <!--[if lt IE 8]>
            <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
        <![endif]-->
        <hr id="starter" />

        <div id="header">
          <div class="row">
            <div class="two columns"></div>
            <div class="eight columns">
              <h1><span id="goHome" onclick="javascript:location.href='/';">Delta Thoughts</span></h1>
              <p class="lead" style="margin-top: -10px;">
                "Pure mathematics is, in its way, the poetry of logical ideas." &mdash; Albert Einstein
              </p>
            </div>

          </div>
        </div>
        <div class="content row">
          <div class="two columns"></div>
          <div class="eight columns">
            <div class="mainIntro">
              <div id="headline">
                Pleasing Panormas and Matrix Multiplication
              </div>
              <div class="date" style="margin-left:0px!important;">By <a href="/">Adi Mittal</a> &#183; August 6, 2022 &#183; 24 min read</div>
            </div>
            <div class="articleBody firstcharacter">
              <p>Out of all the apps on my phone, the camera is one that I can&#39;t see myself without anymore. Between being out with friends, or travelling with family, the camera rarely remains idle as I capture memories forever. Though, there is one particular feature of mobile photography I&#39;ve come to especially love: the panorama.</p>
<p><img src="/img/panorama-homography/grandCanyonEx.jpg"></p>
<center style="color: #666;">
<p>Even this struggles to capture how well the Grand Canyon lives up to its name.</p>
</center>

<p>If you have an Android phone, you can get even more incredible types of otherwise impossible photos with Google&#39;s staple Photo Spheres:</p>
<p><img src="/img/panorama-homography/PHOTOSPHERE.jpg"></p>
<center style="color: #666;">
<p>An &quot;unwrapped&quot; Photo Sphere; normally this would be an interactive literal sphere of the environment.</p>
</center>

<p>While these are cool, it does beg the question: how are these made? How does your phone unite multiple images into a single cohesive one? We&#39;ll explore a little bit of linear algebra to manipulate our photos exactly how we want to.</p>
<h2 id="the-problem">The Problem</h2>
<p>Before anything else, let&#39;s first define what a panorama is. In computer graphics, a panorama is a type of <strong>mosaic</strong>, that is, a unification of two or more images. A panorama in particular, though, is a mosaic in which all the photos to be stitched together are all taken from the same camera position. When you take a panorama on your phone, all you&#39;re doing is spinning in place, so that&#39;s what we want to recreate.</p>
<!-- inset image -->
<p>So, if we&#39;re given two images from different angles, </p>
<p><img src="/img/panorama-homography/desk1.jpg">
<img src="/img/panorama-homography/desk2.jpg"></p>
<p>how do we combine them into a single unified image? Thinking about it this way is not super helpful, since, well, that&#39;s what we already know about panoramas. What do we want to get out of a panorama? If our panorama is done well, then objects in one image should overlap properly with the same objects in the other image.</p>
<p>For example, take a look at the top left of my computer monitor:</p>
<p><img src="/img/panorama-homography/desk1Corner.jpg">
<img src="/img/panorama-homography/desk2Corner.jpg"></p>
<p>In our panorama, these two points should overlap, since we obviously recognize these to be the same object in the real world. But to the two pictures, they are wildly different! In the first picture, the corner of my monitor is closer to the left side of the frame, while in the second picture, it is almost on the top-right edge of the image. So, if we try to manually align these two corners so that they overlap, we get:</p>
<p><img src="/img/panorama-homography/firstPanoAttempt.jpg"></p>
<p>While our single corner of the monitor is aligned between the two images, but I don&#39;t think I have to try very hard to convince you this isn&#39;t a great panorama. I mean, just look at the rest of the overlap.</p>
<p><img src="/img/panorama-homography/firstOverlap.jpg"></p>
<p>The skew angles of the resting laptop and the monitor itself don&#39;t align at all, and while my cable management is bad, it&#39;s not <em>that</em> bad. This is the real challenge at the heart of making panoramas: images are <em>flat</em>, while the motion of a panorama is <em>cylindrical</em>. Ideally we would take a &quot;cylindrical&quot; photo and unwrap that into a rectangle, but we can&#39;t. Undoubtedly, we will have to warp our images somehow to align.</p>
<p>How do we find the right way to warp our image? The first thing we will need to do is get more data! Having one point line up between the photos is not great, but, say, 10 different data points might not be bad.</p>
<p><img src="/img/panorama-homography/desk1labels.jpg">
<img src="/img/panorama-homography/desk2labels.jpg"></p>
<p>So, our final panorama would like the same numbered red and blue points to overlap. With data to use, the second thing we will need is a way to actually warp our image; how do we actually make our point between photos line up? For that, we turn to linear algebra.</p>
<h2 id="rethinking-coordinates">Rethinking Coordinates</h2>
<p>If you had a random ordinary point, how might you describe its position to someone?</p>
<p><img src="/img/panorama-homography/point.png"></p>
<center style="color: #666;">
<p>A lonely, solitary point living in the plane.</p>
</center>

<p>A common choice we&#39;re all familiar with in some way is by using a <strong>coordinate system</strong>. That is, we define a place to be $(0,0)$ and locate every point relative to that <strong>origin</strong> in terms of its $x$ and $y$ coordinates $(x,y)$.</p>
<p><img src="/img/panorama-homography/coordinateSpace.png"></p>
<center style="color: #666;">
<p>A still lonely, solitary point living in the plane, but with more lines.</p>
</center>

<p>In the above coordiante space choice, we might say the point is at $(3,2)$. But what exactly do we <em>mean</em> by the point being at $(3,2)$? What this really implies is that the point is 3 steps to the right of the origin, and 2 steps above the origin.</p>
<p><img src="/img/panorama-homography/basis.png"></p>
<p>So, instead of thinking of this point in terms of separate coordinates, we can think of it in terms of these two <strong>basis vectors</strong>. Let&#39;s use $\color{blue}{i}$ to represent the blue, horizontal vector, and $\color{red}{j}$ to represent the red, vertical vector. So really, our point is really the combination of $\color{blue}{3i}$ and $\color{red}{2j}$, or simply, $\color{blue}{3i} + \color{red}{2j}$, which itself repsents another vector.</p>
<p>This might seem extra and unnecessary, since we just rewrote a vector as the sum of its horizontal and vertical components, which is what coordinates literally do in the first place. But the useful insight here is that we now rewrite points in multiple ways depending on our choice of $\color{blue}{i}$ and $\color{red}{j}$; nothing says our basis vectors have to be in the unit directions! </p>
<p><img src="/img/panorama-homography/basisNew.png"></p>
<center style="color: #666;">
<p>A new, quirky choice of basis vectors.</p>
</center>

<p>With a new choice of basis vectors, the vector $\color{blue}{3i} + \color{red}{2j}$ has a totally new position as that now encodes the coordinate $(5,3)$ since neither $\color{blue}{i}$ nor $\color{red}{j}$ represents horizontal or vertical steps anymore, but rather skew, diagonal steps. </p>
<p>But look at that! We&#39;ve basically accomplished our goal of warping points! We&#39;ve managed to transform the point $(3,2) \rightarrow (5,3)$ by manipulating $\color{blue}{i}$ and $\color{red}{j}$; both points are techincally at $\color{blue}{3i} + \color{red}{2j}$, just for different basis vectors.</p>
<p>This is what linear algebra and matrices encode geometrically. If we write our basis vectors $\color{blue}{i}$ and $\color{red}{j}$ in a matrix and multiply that by the vector representing our initial point, we will get a new point representing our transformation (a.k.a., our warp). How do we write our basis vectors in a matrix? Each vector implicitly has coordinates associated with themselves! In the above picture, $\color{blue}{i}$ points at $(1,-1)$, since from its tail to its tip it moves one step to the right and one step down. $\color{red}{j}$, on the other hand, points at $(1,3)$, and these are precisely the vectors we see in our matrix.</p>
<p>For the unit basis vectors that point at $(1,0)$ and $(0,1)$, we call them $\color{blue}{\hat{\imath}}$ and $\color{red}{\hat{\jmath}}$, and their respective matrix the <em>identity matrix</em>.</p>
<p><img src="/img/panorama-homography/matrixMult.png"></p>
<center style="color: #666;">
<p>The underlying idea of linear transformations.</p>
</center>

<p>These $2 \times 2$ matrices represent <em>linear transformations</em>. They&#39;re transformations in they way that they transform points from one coordinate to another, and they are linear in the sense that keep all grid lines parallel, evenly spaced and, well, linear after the transformation. This is best seen through <a href="https://youtu.be/kYB8IZa5AuE?t=227">video</a> and not stills. For this post you don&#39;t need to understand the mechanics of matrix-vector multiplication, but just understand that it represents some transformation on a point.</p>
<h2 id="warping-images">Warping Images</h2>
<p>So why should we care? Why is this helpful in any way? If we think of each pixel on our images as a coordinate, we can just apply our transformation to all pixels on that image and generate a new image. Let&#39;s take this picture as an example.</p>
<p><img src="/img/panorama-homography/canyon.jpg"></p>
<p>We can scale it, rotate it, or even shear it by applying the same transformation matrix to every pixel.</p>
<p><img src="/img/panorama-homography/warpImage.jpg"></p>
<center style="color: #666;">
<p>An example transformation acting on our image.</p>
</center>

<p>But we have a <em>big</em> problem here: the typical linear transformation does not allow for translations. By the qualities of linear transformations, the origin cannot move, therefore forcing the bottom left corner of our images to always overlap! That&#39;s pretty restrictive in terms of the panoramas we can make—and for practical purposes—a complete nonstarter. If we want to continue through with making a panorama, we&#39;ll need to find a way around translations.</p>
<h3 id="homogenous-coordinates-and-affine-transformations">Homogenous Coordinates and Affine Transformations</h3>
<p>There&#39;s a very sneaky workaround being confined to the origin. To do so, we&#39;ll need to do something that might seem a bit weird to do translations. Let&#39;s rewrite our 2D points with a <em>3rd</em> coordinate. For a given $(x,y)$, let&#39;s rewrite that with a $z$-coordinate $(x,y,1)$. If $z \neq 1$, then we can just divide all the other coordinates by $z$ to make it equal to 1: $(x,y,w) \rightarrow (\frac{x}{w}, \frac{y}{w}, 1)$ (we generally use $w$ to represent the $z$-coordinate to indicate that there is no &quot;real&quot; $z$ value since everything is projected into 2D; we use $w$ as a &quot;weight&quot; to say how much we scale our projections down to). This means we have multiple coordinates represent the same point. In this way, $(2,5,1)$ and $(4,10,2)$ and $(-3,-7.5,-1.5)$ and $(2w,5w,w)$ all represent the same point (we don&#39;t include points when $z=0$ as it represents a point at infinity).</p>
<p>This might seem arbitrary, but what we&#39;re doing here is not too different than our original, 2-coordinate system. When we look at a cross-section of the $xyz$ coordinate space, it looks exactly like the $xy$ plane. What we are doing here is projecting all of $xyz$ space onto the plane $z=1$. </p>
<p><img src="/img/panorama-homography/homogeneousCoords.png"></p>
<center style="color: #666;">
<p>The geometry of projecting points onto $z=1$ is equivalent to finding drawing line through the origin and the point, and finding where it intersects that plane.</p> 
</center>

<p>In fact, many of you are already familiar with <strong>homogeneous coordinates</strong> (representing 2D points with a 3rd scalar coordinate) and <strong>projective planes</strong>! When you take a photo on your phone, how does the camera know what&#39;s drawn in its frame? How does it take a 3-dimensional world and put it into a 2-dimensional picture? The many light rays that enter the camera lens (the origin) will intersect a plane ($z=1$) based on its focal length, and colors the pixel based on the projection.</p>
<p><img src="/img/panorama-homography/projectivePlane.png" style="width: 400px"></p>
<center style="color: #666;">
<p>A photo is homogeneous coordinates in disguise. While there&#39;s many sides to the building, our camera only cares about what it sees in front of it (a.k.a., what gets projected onto the frame). Our worldview is contained to a small projection.</p>
</center>

<p>Using this analogy with photos, clearly translations should be possible! If you&#39;ve seen any cat videos on the internet, clearly it is possible for the cat to enter and exit the frame freely without the camera necessarily moving, and that is precisely possible due to the fact the origin $(0,0,0)$ is not contained in our projective plane $z=1$, since all of our basis vectors have to stem out of the origin! (For those interested a translation matrix is equivalent to a shear along the $z$-axis.)</p>
<p>Think about what we&#39;re doing here: we&#39;re turning a linear transformation in 3-dimensions to create special non-linear <strong>affine transformations</strong> in 2-dimensions! When I first learned this geometrically, awe can&#39;t encapsulate the total shock I felt. So, if we&#39;re given a point $p$, we can transform it with a matrix $M$ to get its image $p&#39;$.</p>
<center>
$
Mp =
\begin{bmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; i 
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1 
\end{bmatrix}
=
\begin{bmatrix}
wx&#39; \\
wy&#39; \\
w \\ 
\end{bmatrix}
=
\begin{bmatrix}
x&#39; \\
y&#39; \\
1 \\ 
\end{bmatrix}
$
</center>

<p>These projections with homogeneous coordinates are known as <strong>homographies</strong>. When we take one picture, and reproject it according to a matrix like this but <em>keeping the same camera center</em> (like the origin), we call it a homography. Again, like homogeneous coordinates, people have been leveraging homographies artistically for a while now. That weird, perspective stree art you might have seen before? That&#39;s the most manual you can get to using homographies—literally warping images with the angle you look at them to make them appear at a normal proportion.</p>
<p><img src="/img/panorama-homography/manual-homography.jpeg"></p>
<center style="color: #666;">
<p>Street artists have used the power of perspective for a long time.</p>
</center>

<p>What we&#39;re doing is computing a homography to build a <strong>mosaic</strong>. Just like the decorative tile art, we are taking tiles of photos that we transform to overlap, and them stitching them all together into one, broader image.</p>
<p>Moreover, our homographies have a really funny interpretation to them. Since we are reprojecting pictures, what it geometrically looks like is that we&#39;re taking two photos which should be rotated in space (as you would spin taking the panorama), and <em>taking a photo of the two photos</em>. Photo-ception.</p>
<p><img src="/img/panorama-homography/photoception.png"></p>
<center style="color: #666;">
<p>If you take a photo of two existing photos, you get one photo that unites the two together. If we can find out the right way to take the photo such that the overlap is correct, we get a panorama.</p>
</center>

<p>There are other ways to reproject images to make other mosaics with the own benefits and downsides, but this is what we&#39;ll use for now. Benefits with this type of mosaics? They are (relatively) easy and fast(er) to compute. Downsides? We can only take panoramas up to 180° wide.</p>
<h2 id="one-slight-issue-">One Slight Issue…</h2>
<p>While it&#39;s great that we are able to transform points with matrices, let me remind us what our goal is.</p>
<p><img src="/img/panorama-homography/desk1labels.jpg">
<img src="/img/panorama-homography/desk2labels.jpg"></p>
<p>We have these two photos, where we want to transform one image&#39;s points to overlap with the other&#39;s. In terms of our matrix arithmetic from before, we have $p$ and $p&#39;$, but no matrix $M$... Up to this point we have been finding our image points using our own matrices, but how do we find that intermediate matrix given a point and its image?</p>
<h2 id="regressions-and-4-dimensional-lines">Regressions and 4-Dimensional Lines</h2>
<p>Like homogeneous coordinates, many of you will already be familiar with solving for the intermediate matrix given a $p$ and $p&#39;$. Let&#39;s do it with a simpler example.</p>
<p>If you had the points $(1,2)$ and $(6,4)$, and I needed you to find the line $y=mx+b$ that went through them, most of you would be able to do that. We&#39;d set up a system of linear equations</p>
<center>
$\begin{align}
2 &amp; = m(1) + b \
\newline
4 &amp; = m(6) + b
\end{align}$
</center>

<p>and solve for $m$ and $b$ respectively. In this case, $m=\frac{2}{5}$ and $b=\frac{8}{5}$. Simple algebra with little to worry about here. What is important to note here is that we <em>could</em> solve for a unique $m$ and $b$, since two points define one unique line.</p>
<p><img src="/img/panorama-homography/ordinaryLine.png"></p>
<center style="color: #666;">
<p>An ordinary line going between two points.</p>
</center>

<p>But what if I introduced a third point $(p_3,p_3&#39;)$? Or even a 4th point $(p_4,p_4&#39;)$? How do we draw a line through those 4 points? There might be a line that goes through all 4 points, but it&#39;s highly unlikely.</p>
<p><img src="/img/panorama-homography/linRegression.png"></p>
<center style="color: #666;">
<p>While there&#39;s no one line through all 4 points, what&#39;s the <em>closest</em> to a line we can get?</p>
</center>

<p>We may not have <em>exact</em> values for $m$ and $b$, but what&#39;s the best value for both to get the <em>closest</em> solution to this system of equations?</p>
<center>
$\begin{align}
p_1&#39; &amp; = m(p_1) + b \
\newline
p_2&#39; &amp; = m(p_2) + b \
\newline
p_3&#39; &amp; = m(p_3) + b \
\newline
p_4&#39; &amp; = m(p_4) + b
\end{align}$
</center>

<p>That&#39;s a task as simple as plugging it into a spreadsheet and doing a <strong>linear regression</strong>. More specifically, we can use the common <strong>least-squares regression</strong> where we want to minimize not the sum of the errors, but the sum of the square of the errors (as the name would suggest). For those a little more comfortable working with matrices and linear algebra, here&#39;s a <a href="#aside-least-squares-with-linear-algebra">more in-depth explanation</a> of what we&#39;re doing with our data when finding a regression.</p>
<p>To many, this might seem like an obvious thing to do; everyone from middle schoolers to office workers have been finding trend lines forever. But what we did here is pretty useful when we think more abstractly: given a system of linear equations that correlated independent data $p$ with their dependent data $p&#39;$, we were able to solve for the best coefficients of that system of linear equations that most closely solved the system (in the previous case was $m$ and $b$). Finding a line was a nice byproduct, but what we&#39;re really doing here is solving that system of linear equations.</p>
<p>Now I promise this will be helpful. Let&#39;s look at our original expanded matrix equation of $Mp = p&#39;$.</p>
<center>
$
\begin{bmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; 1 
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1 
\end{bmatrix}
=
\begin{bmatrix}
wx&#39; \\
wy&#39; \\
w \\ 
\end{bmatrix}
$
</center>

<p>Remember, we&#39;re working in homogeneous coordinates, so $p&#39;$ might not land on the plane $z=1$, and we account for that with $w$ here. I also set $i=1$, since a) that corresponds with a certain scaling and is not necessarily unique vector, but more importantly b) gives us one less variable to solve for.</p>
<p>Here, we will need to actually do the matrix-vector multiplication. Carrying it out nets a system of linear equations! (I know I said you won&#39;t need to know the mechanics of these operations, but it&#39;s hard to avoid it now. If you can accept this fact, that&#39;s great, but I&#39;d recommend looking <a href="https://youtu.be/XkY2DOUCWMU">here</a> if you are unfamiliar.) </p>
<center>
$\begin{align}
ax + by + c &amp; = wx&#39; \
\newline
dx + ey + f &amp; = wy&#39; \ 
\newline
gx + hy + 1 &amp; = w
\end{align}$
</center>

<p>Using the third equation in tandem with the first two…</p>
<center>
$\begin{align}
ax + by + c &amp; = (gx + hy + 1)x&#39; \
\newline
dx + ey + f &amp; = (gx + hy + 1)y&#39; 
\end{align}$
</center>

<p>Just like before, we can solve for $a$, $b$, $c$, $d$, $e$, $f$, $g$, and $h$ with a least-squares regression like before! Since we have 8 variables, at minimum we need 8 equations or 4 pairs of $p$ and $p&#39;$ (since each pair contains two equations: one for $x&#39;$ and one for $y&#39;$). Though, just like we have 10 points, generally it is better to have more data and overfit than less (we&#39;d rather have an overall average fit, than just 4 points be <em>exatly</em> where we want them to be). It&#39;s weird to think of this geometrically, since what we&#39;re doing here is not finding the line between one independent variable and one dependent variable, but rather <em>two</em> independent variables $(x,y)$ with <em>two</em> corresponding dependent variables $(x&#39;,y&#39;)$; our regression exists in 4-dimensions!</p>
<h2 id="putting-it-all-together">Putting It All Together</h2>
<p>Let&#39;s quickly reflect on what we&#39;ve covered thus far.</p>
<ol>
<li>We&#39;ve redefined coordinates purely with vectors, allowing us to nicely compact our image-warping transformations in matrices.</li>
<li>Our original definition of coordinates failed to include translations—a key transformation. We described 2-dimensional points in 3-dimensions with homogeneous coordinates, resolving our worries.</li>
<li>We then ran into ANOTHER problem in that while we knew how to warp images <em>given</em> the transformation matrix, we really wanted to be able to find the matrix given a starting point and an end point to map to.</li>
<li>Using a least-squares regression, we were able to turn our unknown matrix equation into a system of linear equations that were much easier to work with to compute our homography (sort of, see the <a href="#aside-least-squares-with-linear-algebra">aside</a> below).</li>
</ol>
<p>Let&#39;s use this first photo to give our list of points $p$.</p>
<p><img src="/img/panorama-homography/desk1labels.jpg"></p>
<p>And we&#39;ll try to match those red points to these blue points on the second photo: our list of $p&#39;$.</p>
<p><img src="/img/panorama-homography/desk2labels.jpg"></p>
<p>Having the computer compute the transformation matrix, we take that matrix and multiply every pixel (remember, treating them as coordinates/vectors), and warping the first image. Then, we can overlay them to see how close our points line up! If our points were well selected, and our computed homography—with the least-squares regression—has minimal error, we should get a pretty decent attempt at a panorama.</p>
<p><img src="/img/panorama-homography/firstPano.jpg"></p>
<p>Sure, the blending isn&#39;t great, and it didn&#39;t <em>completely</em> fix the overlap issue, but the seams and photo stitching definitely is much nicer! And honestly, it&#39;s pretty cool seeing how the image was transformed and finding the outline of the images cross like that.</p>
<p><img src="/img/panorama-homography/firstPanoOutline.jpg"></p>
<p>With some simple masking and basic filtering, suddenly it really begins to look clean.</p>
<p><img src="/img/panorama-homography/panorama.jpg"></p>
<p>While this is cool, it does reveal another unfortunate downside of our choice of mosaic: we lose lots of data for a uniform picture. </p>
<p><img src="/img/panorama-homography/panoramaCrop.jpg"></p>
<p>Even so, it doesn&#39;t even look that bad. All in all, though, not a bad first attempt at building a panorama.</p>
<h2 id="what-next-">What Next?</h2>
<p>While we have a working prototype, we can do signficantly better. For one, I used only 10 labelled points to compute our homography, but if you use even more, it&#39;s not hard to get a better, and closer fit. With algortihms like <a href="https://zju3dv.github.io/loftr/">LoFTR</a>, finding lots of corresponding labelled points is quick and easy.</p>
<center>
<video width="85%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
      <source src="/img/panorama-homography/loftr-homepage-demo.mp4" type="video/mp4">
</center>
<center style="color: #666;">
<p>Some really smart people made an algorithm specifically to finding high quality object matching between multiple photos. Credit: LoFTR Team</p>
</center>

<p>Also, since we are manually constructing our panorama, we can stitch and blend photos that have no right being together in a panorama.</p>
<p><img src="/img/panorama-homography/lightdark2.jpg"></p>
<center style="color: #666;">
<p>Going from a well-lit to a dark photo makes for some artsy renditions (even more if you blend it a little nicer).</p>
</center>

<p>We never really touched on our homographies, either. When we decided 10 initial points $p$ and 10 warped points $p&#39;$, our $p&#39;$ was decided as a result of lining up 2 photos. What if we didn&#39;t want to line up multiple photos, but rather just creatively warp a single photos? </p>
<p><img src="/img/panorama-homography/rectification.jpeg"></p>
<center style="color: #666;">
<p>Something not quite lined up? A simple homography can fix that for us.</p>
</center>

<p>This is know as <strong>rectification</strong>, as it is a means to correct for mistakes we might have had in our photo.</p>
<p>Finally, the last improvement we can make to our mosaics is trying new projections and warpings. If we want something even as simple as just wider, up to 360°, full views, we&#39;ll need to find something more robust than our previous approach. Or what if we wanted to make something akin to a full photosphere like from before?</p>
<p><img src="/img/panorama-homography/PHOTOSPHERE.jpg"></p>
<p>What we did today was simply <strong>planar projection</strong>, or just reprojection onto a plane. We did that with homogenous coordinates. For wider, more complete mosaics, we&#39;ll need either <strong>cylindrical</strong> or <strong>spherical projection</strong>, which is exactly what it sounds like. For more on this, I recommend reading these <a href="https://inst.eecs.berkeley.edu/~cs194-26/fa21/Lectures/MoreMosaics.pdf">slides from UC Berkeley</a>&#39;s CS 194-26, their introductory computer vision and computational photography class.</p>
<p>I hope this gave an interesting peak at the intersection of linear algebra and photography, and more over, I hope this gave you an appreciation for the math your phone goes through every time you take a panorama. </p>
<p>If you&#39;re interested, here&#39;s a link to a <a href="https://colab.research.google.com/drive/1bgOaBnHTlKx-DYfLg2HmtsaFekWgwJFn?usp=sharing">Python notebook</a> where you can see some of my experiments during my struggle and exploration with panoramas and homographies.</p>
<hr>
<h2 id="aside-least-squares-with-linear-algebra">Aside: Least-Squares with Linear Algebra</h2>
<p>Okay, this previous section is really hard to describe without already knowing a fair amount of linear algebra, and it felt a little flat without having a more methodical procedure of solving a least-squares regression. I wasn&#39;t planning on including this section, but it felt incomplete otherwise. For those interested, feel free to peer over it, but this is not necessary within the scope of this post; all you need to understand is what our regression is accomplishing, thinking of that &quot;line of best fit&quot; idea.</p>
<p>Let&#39;s go back to when we were trying to find a line between two points. If you have 2 points, $(p_1, p_1&#39;)$ and $(p_2, p_2&#39;)$ being fit to the line $y=mx+b$, we have a system of linear equations like before.</p>
<center>
$\begin{align}
p_1&#39; &amp; = m(p_1) + b \
\newline
p_2&#39; &amp; = m(p_2) + b
\end{align}$
</center>

<p>We can solve this just like we did before to find $m$ and $b$, but there&#39;s a secret matrix equation embedded into this system. </p>
<center>
$
\begin{bmatrix}
p_1&#39; \\
p_2&#39;
\end{bmatrix}
=
\begin{bmatrix}
p_1 &amp; 1 \\
p_2 &amp; 1
\end{bmatrix}
\begin{bmatrix}
m \\
b
\end{bmatrix}$
</center>

<p>In a sense, that&#39;s what a matrix is: a system of linear equations, and you can freely go between either a system of linear equations or a matrix via matrix multiplication. (I know I said you won&#39;t need to know the mechanics of these operations, but it&#39;s hard to avoid it now. If you can accept this fact, that&#39;s great, but I&#39;d recommend looking <a href="https://youtu.be/XkY2DOUCWMU">here</a> if you are unfamiliar.)</p>
<p>If we write this in general terms, we are basically solving the equation</p>
<center>
$b = Ax$
</center>

<p>where $A$ is a matrix, and $b$ and $x$ are vectors, and we are solving for the latter. It might seem pointless to rewrite it, but what we&#39;re actually solving is</p>
<center>
$Ax - b = 0$
</center>

<p>Since $Ax$ is <em>exactly</em> equal to $b$; $Ax$ is the same vector as to $b$. We were able to find a unique line with $m$ and $b$ through them, no? Just as we were able to solve the system of linear equations before, we can easily solve this with matrix inverses:</p>
<center>
$A^{-1}b = x$
</center>

<p>Now, let&#39;s add more points.</p>
<center>
$\begin{align}
p_1&#39; &amp; = m(p_1) + b \
\newline
p_2&#39; &amp; = m(p_2) + b \
\newline
p_3&#39; &amp; = m(p_3) + b \
\newline
p_4&#39; &amp; = m(p_4) + b
\end{align}$
</center>

<p>Now we turn this into a matrix equation like before.</p>
<center>
$
\begin{bmatrix}
p_1&#39; \\
p_2&#39; \\
p_3&#39; \\
p_4
\end{bmatrix}
=
\begin{bmatrix}
p_1 &amp; 1 \\
p_2 &amp; 1 \\
p_3 &amp; 1 \\
p_4 &amp; 1
\end{bmatrix}
\begin{bmatrix}
m \\
b
\end{bmatrix}$
</center>

<p>We know that there&#39;s a good chance our four points don&#39;t all lie on the same line. So it&#39;s unlikely that $Ax - b = 0$. We want to get a line that gets <em>as close</em> to being a line. So our goal is to </p>
<center>
$\min||Ax-b||^2$
</center>

<p>Also, now that $A$ is no longer a square matrix, so we can&#39;t simply take its inverse to solve our equation anymore, since it doesn&#39;t have an inverse. However, we can use the following facts to easily deduce a solution. I&#39;ll let <a href="https://textbooks.math.gatech.edu/ila/least-squares.html">Georgia Tech</a> explain the conditions and proof succinctly:</p>
<hr>
<p><strong>Theorem.</strong> Let $A$ be a $m \times n$ matrix and let $b$ be a vector in $\mathbb{R}^m$. The following are equivalent:</p>
<ol>
<li>$Ax=b$ has a unique least-squares solution.</li>
<li>The columns of $A$ are linearly independent.</li>
<li>$A^TA$ is invertible.</li>
</ol>
<p>In this case, the least-squares solution is</p>
<center>
$x = (A^{T}A)^{-1}A^{T}b$
</center>

<p><strong>Proof.</strong> The set of least-squares solutions of $Ax = b$ is the solution set of the consistent equation $A^TAx = A^Tb$, which is a translate of the solution set of the homogeneous equation $A^TAx = 0$. Since $A^TAx$ is a square matrix, the equivalence of [facts] 1 and 3 follows from the invertible matrix theorem. The set of least squares-solutions is also the solution set of the consistent equation $Ax=b_{\textrm{Col}(A)}$, which has a unique solution if and only if the columns of A are linearly independent. </p>
<hr>
<p>Basically, it says if our system of linear equations contain only unique equations (i.e. no one equation is a multiple of another), we can turn our non-square matrix $A$ into a square one by multiplying by its transpose $A^T$, and solve our least squares the way we&#39;d solve it before with inverses. In other words, if our matrix follows the criteria listed above, our minimizing solution comes from creating an equivalent equation with an invertible matrix:</p>
<center>
$\begin{align}
Ax &amp; = b \
\newline
A^TAx &amp; = A^Tb \
\newline
(A^TA)^{-1}A^TAx &amp; = (A^TA)^{-1}A^TAb \
\newline
x &amp; = (A^TA)^{-1}A^TAb
\end{align}$
</center>

<p>Now, let&#39;s recall the our matrix equation from before of the homography we wanted to solve. </p>
<center>
$
\begin{bmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
g &amp; h &amp; 1 
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1 
\end{bmatrix}
=
\begin{bmatrix}
wx&#39; \\
wy&#39; \\
w \\ 
\end{bmatrix}
$
</center>

<p>Then, we expanded this into 3 linear equations, and further simplified them to the following two:</p>
<center>
$\begin{align}
ax + by + c &amp; = (gx + hy + 1)x&#39; \
\newline
dx + ey + f &amp; = (gx + hy + 1)y&#39; 
\end{align}$
</center>

<p>This, can be rewritten as another, secret matrix equation:</p>
<center>
$
\begin{bmatrix}
x &amp; y &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; -x&#39; \cdot x &amp; -x&#39; \cdot y \\
0 &amp; 0 &amp; 0 &amp; x &amp; y &amp; 1 &amp; -y&#39; \cdot x &amp; -y&#39; \cdot y
\end{bmatrix}
\begin{bmatrix}
a \\
b \\
c \\
d \\
e \\
f \\
g \\
h 
\end{bmatrix}
=
\begin{bmatrix}
x&#39; \\
y&#39;
\end{bmatrix}
$
</center>

<p>Wait, we turned our original matrix equation into another one? As awful as that may look, this is much more useful than our original equation since now, all of our unknowns are in a vector; it really is no different than our previous least-squares examples, and we&#39;re still solving for the vector $x$ in</p>
<center>
$Ax = b$
</center>

<p>So, we can still solve it like before finding </p>
<center>
$x = (A^{T}A)^{-1}A^{T}b$
</center>

<p>And with that, we now have also gone through what our program is doing under the hood, and have gone through some of the tedium of justifying what a least-squares regression is from a linear algebra perspective.</p>

              <div id="disqus_thread"></div>
            <script>
                (function() {  // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');

                    s.src = '//delta-thoughts.disqus.com/embed.js';

                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
            </div>
          </div>
          <div class="two columns"></div>
        </div>

        <script src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js"></script>
        <script type="text/javascript">
          window.MathJax = {
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              processEscapes: true
            }
          };
        </script>
        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script>
            (function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=
            function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;
            e=o.createElement(i);r=o.getElementsByTagName(i)[0];
            e.src='//www.google-analytics.com/analytics.js';
            r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));
            ga('create','UA-101583586-1','auto');ga('send','pageview');
        </script>
    </body>
</html>